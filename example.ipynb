{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaesu26/vime/blob/main/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75xRhMA-ZZ4g"
      },
      "source": [
        "# VIME Example"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`-` An example to train VIME-Self and VIME-Semi using google colab gpu"
      ],
      "metadata": {
        "id": "6VoY9QtMugOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone Repository"
      ],
      "metadata": {
        "id": "URy6aEW-cIML"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjvmmVOVMW_P",
        "outputId": "e6789823-4b69-46d5-8965-c1578e8ffec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/vime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcJwBS1jt4J2",
        "outputId": "5a7e8ec3-21b2-4fe2-9277-d478428278e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/vime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Jaesu26/vime.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ncytT-2biR8",
        "outputId": "b7b75b99-a8e6-4d90-d547-bb83e634995f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vime'...\n",
            "remote: Enumerating objects: 150, done.\u001b[K\n",
            "remote: Counting objects: 100% (150/150), done.\u001b[K\n",
            "remote: Compressing objects: 100% (98/98), done.\u001b[K\n",
            "remote: Total 150 (delta 91), reused 106 (delta 50), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (150/150), 21.07 KiB | 1.62 MiB/s, done.\n",
            "Resolving deltas: 100% (91/91), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r vime/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53Q9JcErb5-j",
        "outputId": "42aa49ea-053c-4a37-aa97-c891e8854914"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from -r vime/requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r vime/requirements.txt (line 2)) (2.0.0+cu118)\n",
            "Collecting lightning>=2.0.0 (from -r vime/requirements.txt (line 3))\n",
            "  Downloading lightning-2.0.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from -r vime/requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r vime/requirements.txt (line 2)) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r vime/requirements.txt (line 2)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r vime/requirements.txt (line 2)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r vime/requirements.txt (line 2)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r vime/requirements.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r vime/requirements.txt (line 2)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2.0.0->-r vime/requirements.txt (line 2)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2.0.0->-r vime/requirements.txt (line 2)) (16.0.2)\n",
            "Requirement already satisfied: PyYAML<8.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->-r vime/requirements.txt (line 3)) (6.0)\n",
            "Collecting arrow<3.0,>=1.2.0 (from lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->-r vime/requirements.txt (line 3)) (4.11.2)\n",
            "Requirement already satisfied: click<10.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->-r vime/requirements.txt (line 3)) (8.1.3)\n",
            "Collecting croniter<1.4.0,>=1.3.0 (from lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading croniter-1.3.14-py2.py3-none-any.whl (18 kB)\n",
            "Collecting dateutils<2.0 (from lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\n",
            "Collecting deepdiff<8.0,>=5.7.0 (from lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading deepdiff-6.3.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi<0.89.0,>=0.69.0 (from lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading fastapi-0.88.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec<2024.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->-r vime/requirements.txt (line 3)) (2023.4.0)\n",
            "Collecting inquirer<5.0,>=2.10.0 (from lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading inquirer-3.1.3-py3-none-any.whl (18 kB)\n",
            "Collecting lightning-cloud>=0.5.34 (from lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading lightning_cloud-0.5.34-py3-none-any.whl (557 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-utilities<2.0,>=0.7.0 (from lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->-r vime/requirements.txt (line 3)) (23.1)\n",
            "Requirement already satisfied: psutil<7.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->-r vime/requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: pydantic<4.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->-r vime/requirements.txt (line 3)) (1.10.7)\n",
            "Requirement already satisfied: requests<4.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->-r vime/requirements.txt (line 3)) (2.27.1)\n",
            "Requirement already satisfied: rich<15.0,>=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->-r vime/requirements.txt (line 3)) (13.3.4)\n",
            "Collecting starlette (from lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starsessions<2.0,>=1.2.1 (from lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting torchmetrics<2.0,>=0.7.0 (from lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->-r vime/requirements.txt (line 3)) (4.65.0)\n",
            "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->-r vime/requirements.txt (line 3)) (5.7.1)\n",
            "Requirement already satisfied: urllib3<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->-r vime/requirements.txt (line 3)) (1.26.15)\n",
            "Collecting uvicorn<2.0 (from lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: websocket-client<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->-r vime/requirements.txt (line 3)) (1.5.1)\n",
            "Collecting websockets<12.0 (from lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading websockets-11.0.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning (from lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading pytorch_lightning-2.0.2-py3-none-any.whl (719 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.0/719.0 kB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->-r vime/requirements.txt (line 4)) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->-r vime/requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->-r vime/requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow<3.0,>=1.2.0->lightning>=2.0.0->-r vime/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<6.0,>=4.8.0->lightning>=2.0.0->-r vime/requirements.txt (line 3)) (2.4.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateutils<2.0->lightning>=2.0.0->-r vime/requirements.txt (line 3)) (2022.7.1)\n",
            "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff<8.0,>=5.7.0->lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting starlette (from lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading starlette-0.22.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette->lightning>=2.0.0->-r vime/requirements.txt (line 3)) (3.6.2)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec<2024.0,>=2022.5.0->lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting blessed>=1.19.0 (from inquirer<5.0,>=2.10.0->lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-editor>=1.0.4 (from inquirer<5.0,>=2.10.0->lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Collecting readchar>=3.0.6 (from inquirer<5.0,>=2.10.0->lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->-r vime/requirements.txt (line 2)) (2.1.2)\n",
            "Collecting pyjwt (from lightning-cloud>=0.5.34->lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
            "Collecting python-multipart (from lightning-cloud>=0.5.34->lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from lightning-cloud>=0.5.34->lightning>=2.0.0->-r vime/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning>=2.0.0->-r vime/requirements.txt (line 3)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning>=2.0.0->-r vime/requirements.txt (line 3)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning>=2.0.0->-r vime/requirements.txt (line 3)) (3.4)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning>=2.0.0->-r vime/requirements.txt (line 3)) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning>=2.0.0->-r vime/requirements.txt (line 3)) (2.14.0)\n",
            "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from starsessions<2.0,>=1.2.1->lightning>=2.0.0->-r vime/requirements.txt (line 3)) (2.1.2)\n",
            "Collecting h11>=0.8 (from uvicorn<2.0->lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->-r vime/requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning>=2.0.0->-r vime/requirements.txt (line 3)) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning>=2.0.0->-r vime/requirements.txt (line 3))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->lightning>=2.0.0->-r vime/requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning>=2.0.0->-r vime/requirements.txt (line 3)) (0.2.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<15.0,>=12.3.0->lightning>=2.0.0->-r vime/requirements.txt (line 3)) (0.1.2)\n",
            "Requirement already satisfied: setuptools>=41.0 in /usr/local/lib/python3.10/dist-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning>=2.0.0->-r vime/requirements.txt (line 3)) (67.7.2)\n",
            "Installing collected packages: python-editor, websockets, readchar, python-multipart, pyjwt, ordered-set, multidict, lightning-utilities, h11, frozenlist, blessed, async-timeout, yarl, uvicorn, starlette, inquirer, deepdiff, dateutils, croniter, arrow, aiosignal, starsessions, fastapi, aiohttp, lightning-cloud, torchmetrics, pytorch-lightning, lightning\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 arrow-1.2.3 async-timeout-4.0.2 blessed-1.20.0 croniter-1.3.14 dateutils-0.6.12 deepdiff-6.3.0 fastapi-0.88.0 frozenlist-1.3.3 h11-0.14.0 inquirer-3.1.3 lightning-2.0.2 lightning-cloud-0.5.34 lightning-utilities-0.8.0 multidict-6.0.4 ordered-set-4.1.0 pyjwt-2.6.0 python-editor-1.0.4 python-multipart-0.0.6 pytorch-lightning-2.0.2 readchar-4.0.5 starlette-0.22.0 starsessions-1.3.0 torchmetrics-0.11.4 uvicorn-0.22.0 websockets-11.0.2 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68xM6jF0ZchA"
      },
      "source": [
        "## Prepare MNIST"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easydict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMTTJ6Nscw_a",
        "outputId": "325997a8-838c-41e3-f5c7-b27e9a6cdffc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (1.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "import easydict\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "warnings.filterwarnings(\"ignore\") "
      ],
      "metadata": {
        "id": "3d2SUG3UcRka"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN7RHXuYr88l"
      },
      "source": [
        "- Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZBe2gEgzr-q1"
      },
      "outputs": [],
      "source": [
        "args_self = easydict.EasyDict({\n",
        "    \"weights_dirpath\": \"./vimeself_weights\",\n",
        "    \"max_epochs\": 50,\n",
        "    \"batch_size\": 512,\n",
        "    \"train_size\": 0.9,\n",
        "    \"learning_rate\": 1e-2, \n",
        "    \"p_masking\": 0.3,\n",
        "    \"alpha\": 2.0,\n",
        "    \"log_interval\": 5,\n",
        "    \"seed\": 26,\n",
        "})\n",
        "args_semi = easydict.EasyDict({\n",
        "    \"weights_dirpath\": \"./vimesemi_weights\",\n",
        "    \"num_classes\": 10,\n",
        "    \"task_type\": \"multiclass\",\n",
        "    \"max_epochs\": 50,\n",
        "    \"labeled_batch_size\": 128,\n",
        "    \"unlabeled_batch_size\": 1024,\n",
        "    \"train_size\": 0.9,\n",
        "    \"learning_rate\": 1e-3, \n",
        "    \"p_masking\": 0.3,\n",
        "    \"K\": 3,\n",
        "    \"beta\": 1.0,\n",
        "    \"log_interval\": 5,\n",
        "    \"seed\": 26,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_folder(path: str) -> None:\n",
        "    try:\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "    except OSError as error:\n",
        "        print(error)"
      ],
      "metadata": {
        "id": "sAAMbpDRqGj9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_folder(args_self.weights_dirpath)\n",
        "create_folder(args_semi.weights_dirpath)"
      ],
      "metadata": {
        "id": "7q8cqk7NqH_1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRrJ4A5RKC4B"
      },
      "source": [
        "- Load data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "yz7eminncyb4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml(\"mnist_784\")"
      ],
      "metadata": {
        "id": "N7JdJZofCXED"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = mnist.data.values\n",
        "target = mnist.target.astype(int).values"
      ],
      "metadata": {
        "id": "CUujD6TFjqVs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data /= 255.0"
      ],
      "metadata": {
        "id": "nu1JV7JhZJhg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_ZB4UZ0gg7m",
        "outputId": "1e2c0e2c-e58e-4816-e7ee-d3b0eb6e556e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Split data"
      ],
      "metadata": {
        "id": "VyAxwzdFiJpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_labeled_data_used = 1000\n",
        "unlabeled_data_rate = 0.9\n",
        "seed = 26"
      ],
      "metadata": {
        "id": "mvJecY3xh56g"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, X_test, y, y_test = train_test_split(data, target, test_size=1/7, random_state=seed, stratify=target)"
      ],
      "metadata": {
        "id": "2WHvI1h1rW3p"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_labeled, X_unlabeled, y, _ = train_test_split(X, y, test_size=unlabeled_data_rate, random_state=seed, stratify=y)"
      ],
      "metadata": {
        "id": "T3ADeqVXrpV5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_labeled = X_labeled[:num_labeled_data_used]\n",
        "y = y[:num_labeled_data_used]"
      ],
      "metadata": {
        "id": "AQIirdQvsh0I"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VIME"
      ],
      "metadata": {
        "id": "Sk00Z9pJiTUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightning.pytorch as pl\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from vime.vime.datamodules import VIMESelfDataModule, VIMESemiDataModule\n",
        "from vime.vime.lightningmodules import VIMESelf, VIMESemi"
      ],
      "metadata": {
        "id": "snEuPPvPkaG5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VIME Self"
      ],
      "metadata": {
        "id": "9fPv2ys9lGrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create datamodule and model"
      ],
      "metadata": {
        "id": "wCKRinaBmf31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim = X_unlabeled.shape[1]"
      ],
      "metadata": {
        "id": "XUAY2nfcIgfq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "self_datamodule = VIMESelfDataModule(X_unlabeled, train_size=0.9, batch_size=512, seed=args_self.seed)"
      ],
      "metadata": {
        "id": "R9QxnpdZJK_K"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vime_self = VIMESelf(\n",
        "    in_features_list=[dim],\n",
        "    out_features_list=[256],\n",
        "    learning_rate=args_self.learning_rate,\n",
        "    p_masking=args_self.p_masking,\n",
        "    alpha=args_self.alpha,\n",
        "    log_interval=args_self.log_interval,\n",
        "    seed=args_self.seed,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8OQbsLjl-LW",
        "outputId": "55952345-3755-4602-8fb6-b4283fcf7aee"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Global seed set to 26\n",
            "INFO:lightning.fabric.utilities.seed:Global seed set to 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train vime self"
      ],
      "metadata": {
        "id": "YboyGahYLbtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mc = ModelCheckpoint(\n",
        "    dirpath=args_self.weights_dirpath,\n",
        "    filename=\"vime_self\",\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    save_weights_only=True,\n",
        ")\n",
        "\n",
        "es = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=10,\n",
        "    mode=\"min\",\n",
        ")"
      ],
      "metadata": {
        "id": "-QQ0TjD6pgRE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(\n",
        "    accelerator=\"gpu\",\n",
        "    devices=1,\n",
        "    logger=False,\n",
        "    callbacks=[mc, es],\n",
        "    max_epochs=args_self.max_epochs,\n",
        "    num_sanity_val_steps=0,\n",
        "    enable_progress_bar=False, \n",
        "    enable_model_summary=False,\n",
        "    deterministic=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvMFCio-Lecj",
        "outputId": "3699fb7d-6e6b-45cf-8a1a-fbe84bfe37d6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(vime_self, self_datamodule)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWmpH4bvrZ6r",
        "outputId": "aa2658a1-55ec-4eaf-9869-cbdaf41283ba"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.2607 | Val Loss_m: 0.2199 | Val Loss_r: 0.0204\n",
            "Epoch 0 | Train Loss: 0.3272 | Train Loss_m: 0.2400 | Train Loss_r: 0.0436  Val Loss: 0.2429 | Val Loss_m: 0.2118 | Val Loss_r: 0.0155\n",
            "Epoch 5 | Train Loss: 0.2443 | Train Loss_m: 0.2129 | Train Loss_r: 0.0157  Val Loss: 0.2318 | Val Loss_m: 0.2012 | Val Loss_r: 0.0153\n",
            "Epoch 10 | Train Loss: 0.2327 | Train Loss_m: 0.2019 | Train Loss_r: 0.0154  Val Loss: 0.2255 | Val Loss_m: 0.1955 | Val Loss_r: 0.0150\n",
            "Epoch 15 | Train Loss: 0.2264 | Train Loss_m: 0.1960 | Train Loss_r: 0.0152  Val Loss: 0.2225 | Val Loss_m: 0.1926 | Val Loss_r: 0.0149\n",
            "Epoch 20 | Train Loss: 0.2232 | Train Loss_m: 0.1930 | Train Loss_r: 0.0151  Val Loss: 0.2208 | Val Loss_m: 0.1911 | Val Loss_r: 0.0149\n",
            "Epoch 25 | Train Loss: 0.2213 | Train Loss_m: 0.1912 | Train Loss_r: 0.0150  Val Loss: 0.2194 | Val Loss_m: 0.1900 | Val Loss_r: 0.0147\n",
            "Epoch 30 | Train Loss: 0.2198 | Train Loss_m: 0.1901 | Train Loss_r: 0.0148  Val Loss: 0.2188 | Val Loss_m: 0.1892 | Val Loss_r: 0.0148\n",
            "Epoch 35 | Train Loss: 0.2191 | Train Loss_m: 0.1894 | Train Loss_r: 0.0148  Val Loss: 0.2177 | Val Loss_m: 0.1882 | Val Loss_r: 0.0147\n",
            "Epoch 40 | Train Loss: 0.2184 | Train Loss_m: 0.1888 | Train Loss_r: 0.0148  Val Loss: 0.2169 | Val Loss_m: 0.1875 | Val Loss_r: 0.0147\n",
            "Epoch 45 | Train Loss: 0.2177 | Train Loss_m: 0.1881 | Train Loss_r: 0.0148  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VIME Semi"
      ],
      "metadata": {
        "id": "0GyrAB0WkAsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create datamodule and model"
      ],
      "metadata": {
        "id": "4XNHwOUDkFEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim = X_labeled.shape[1]"
      ],
      "metadata": {
        "id": "sUzVLATbkGka"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "semi_datamodule = VIMESemiDataModule(\n",
        "    X_unlabeled,\n",
        "    X_labeled,\n",
        "    y,\n",
        "    X_test,\n",
        "    train_size=0.9,\n",
        "    labeled_batch_size=args_semi.labeled_batch_size,\n",
        "    unlabeled_batch_size=args_semi.unlabeled_batch_size,\n",
        "    seed=args_semi.seed,\n",
        ")"
      ],
      "metadata": {
        "id": "O606x9hWkJS7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_path = mc.best_model_path"
      ],
      "metadata": {
        "id": "LA5UYnLG_jCa"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vime_self_best = VIMESelf.load_from_checkpoint(best_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRq6_xiSivq8",
        "outputId": "213fbf91-9fdd-4688-f03a-32db9b0257b4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Global seed set to 26\n",
            "INFO:lightning.fabric.utilities.seed:Global seed set to 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_encoder = vime_self_best.encoder"
      ],
      "metadata": {
        "id": "kbs1mKr8j1ar"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vime_semi = VIMESemi(\n",
        "    pretrained_encoder=pretrained_encoder,\n",
        "    in_features_list=[256, 128],\n",
        "    out_features_list=[128, 64],\n",
        "    num_classes=args_semi.num_classes,\n",
        "    task_type=\"multiclass\",\n",
        "    learning_rate=args_semi.learning_rate,\n",
        "    p_masking=args_semi.p_masking,\n",
        "    K=args_semi.K,\n",
        "    beta=args_semi.beta,\n",
        "    log_interval=args_semi.log_interval,\n",
        "    seed=args_semi.seed,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJje5q80j7XT",
        "outputId": "223a30a7-6eaa-4c44-d256-46926dcf10be"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Global seed set to 26\n",
            "INFO:lightning.fabric.utilities.seed:Global seed set to 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train vime semi"
      ],
      "metadata": {
        "id": "pBZJVPIvuQ4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mc = ModelCheckpoint(\n",
        "    dirpath=args_semi.weights_dirpath,\n",
        "    filename=\"vime_semi\",\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    save_weights_only=True,\n",
        ")\n",
        "\n",
        "es = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=10,\n",
        "    mode=\"min\",\n",
        ")"
      ],
      "metadata": {
        "id": "Wd6qnZBflzuz"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(\n",
        "    accelerator=\"gpu\",\n",
        "    devices=1,\n",
        "    logger=False,\n",
        "    callbacks=[mc, es],\n",
        "    max_epochs=args_semi.max_epochs,\n",
        "    num_sanity_val_steps=0,\n",
        "    enable_progress_bar=False, \n",
        "    enable_model_summary=False,\n",
        "    deterministic=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR7JwkFnmTzi",
        "outputId": "c549707b-1151-497c-a8ca-6c9438690ad7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(vime_semi, semi_datamodule)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZTVOGenmV1S",
        "outputId": "ff9da4fe-994f-41e3-f981-1a926ca72ea4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss_s: 2.1408\n",
            "Epoch 0 | Train Loss: 1.9603 | Train Loss_s: 1.9093 | Train Loss_u: 0.0510  Val Loss_s: 0.8129\n",
            "Epoch 5 | Train Loss: 0.9396 | Train Loss_s: 0.8622 | Train Loss_u: 0.0774  Val Loss_s: 0.6433\n",
            "Epoch 10 | Train Loss: 0.6104 | Train Loss_s: 0.5061 | Train Loss_u: 0.1042  Val Loss_s: 0.6121\n",
            "Epoch 15 | Train Loss: 0.5356 | Train Loss_s: 0.4106 | Train Loss_u: 0.1250  Val Loss_s: 0.5532\n",
            "Epoch 20 | Train Loss: 0.4913 | Train Loss_s: 0.3541 | Train Loss_u: 0.1373  Val Loss_s: 0.5279\n",
            "Epoch 25 | Train Loss: 0.3867 | Train Loss_s: 0.2485 | Train Loss_u: 0.1383  Val Loss_s: 0.5183\n",
            "Epoch 30 | Train Loss: 0.3723 | Train Loss_s: 0.2312 | Train Loss_u: 0.1411  Val Loss_s: 0.5222\n",
            "Epoch 35 | Train Loss: 0.4436 | Train Loss_s: 0.2998 | Train Loss_u: 0.1437  Val Loss_s: 0.5405\n",
            "Epoch 40 | Train Loss: 0.3767 | Train Loss_s: 0.2293 | Train Loss_u: 0.1474  "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = trainer.predict(vime_semi, semi_datamodule, ckpt_path=mc.best_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgxmkrDLruVA",
        "outputId": "d47165e1-b38e-4777-9c2a-d8b88a04ba1b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Restoring states from the checkpoint path at /content/drive/MyDrive/Colab Notebooks/vime/vimesemi_weights/vime_semi.ckpt\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Restoring states from the checkpoint path at /content/drive/MyDrive/Colab Notebooks/vime/vimesemi_weights/vime_semi.ckpt\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: Loaded model weights from the checkpoint at /content/drive/MyDrive/Colab Notebooks/vime/vimesemi_weights/vime_semi.ckpt\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Loaded model weights from the checkpoint at /content/drive/MyDrive/Colab Notebooks/vime/vimesemi_weights/vime_semi.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.concatenate(pred).argmax(1)"
      ],
      "metadata": {
        "id": "mkczJNKve1Eq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTcKCD-he2o6",
        "outputId": "8a1893ec-2ea4-41fd-c039-9bb51be8e14a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.915"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qnp5gQEigjtr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}