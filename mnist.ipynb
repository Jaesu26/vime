{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaesu26/vime/blob/main/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75xRhMA-ZZ4g"
      },
      "source": [
        "# VIME Example"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`-` An example to train VIME-Self and VIME-Semi using google colab gpu"
      ],
      "metadata": {
        "id": "6VoY9QtMugOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install VIME"
      ],
      "metadata": {
        "id": "URy6aEW-cIML"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjvmmVOVMW_P",
        "outputId": "7ac888c5-9f4e-4c36-f435-d6208f57fbfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/vime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcJwBS1jt4J2",
        "outputId": "051a80f8-868d-40da-f26e-7790d00f612f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/vime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/Jaesu26/vime.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ncytT-2biR8",
        "outputId": "72aebcc1-8230-4af6-e026-38beec6b2764"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/Jaesu26/vime.git\n",
            "  Cloning https://github.com/Jaesu26/vime.git to /tmp/pip-req-build-252xpxpp\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Jaesu26/vime.git /tmp/pip-req-build-252xpxpp\n",
            "  Resolved https://github.com/Jaesu26/vime.git to commit ef83f6be4ce3edfeb45bf37e6b03321a6b6b93df\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from vime==0.0.1) (1.22.4)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from vime==0.0.1) (2.0.1+cu118)\n",
            "Collecting torchmetrics>=0.11.3 (from vime==0.0.1)\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning>=2.0.0 (from vime==0.0.1)\n",
            "  Downloading lightning-2.0.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from vime==0.0.1) (1.2.2)\n",
            "Requirement already satisfied: Jinja2<5.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->vime==0.0.1) (3.1.2)\n",
            "Requirement already satisfied: PyYAML<8.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->vime==0.0.1) (6.0)\n",
            "Collecting arrow<3.0,>=1.2.0 (from lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->vime==0.0.1) (4.11.2)\n",
            "Requirement already satisfied: click<10.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->vime==0.0.1) (8.1.3)\n",
            "Collecting croniter<1.4.0,>=1.3.0 (from lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading croniter-1.3.14-py2.py3-none-any.whl (18 kB)\n",
            "Collecting dateutils<2.0 (from lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\n",
            "Collecting deepdiff<8.0,>=5.7.0 (from lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading deepdiff-6.3.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi<0.89.0,>=0.69.0 (from lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading fastapi-0.88.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec<2024.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->vime==0.0.1) (2023.4.0)\n",
            "Collecting inquirer<5.0,>=2.10.0 (from lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading inquirer-3.1.3-py3-none-any.whl (18 kB)\n",
            "Collecting lightning-cloud>=0.5.34 (from lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading lightning_cloud-0.5.36-py3-none-any.whl (562 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-utilities<2.0,>=0.7.0 (from lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->vime==0.0.1) (23.1)\n",
            "Requirement already satisfied: psutil<7.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->vime==0.0.1) (5.9.5)\n",
            "Requirement already satisfied: pydantic<4.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->vime==0.0.1) (1.10.7)\n",
            "Requirement already satisfied: requests<4.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->vime==0.0.1) (2.27.1)\n",
            "Requirement already satisfied: rich<15.0,>=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->vime==0.0.1) (13.3.4)\n",
            "Collecting starlette (from lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starsessions<2.0,>=1.2.1 (from lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->vime==0.0.1) (4.65.0)\n",
            "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->vime==0.0.1) (5.7.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->vime==0.0.1) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->vime==0.0.1) (1.26.15)\n",
            "Collecting uvicorn<2.0 (from lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: websocket-client<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.0->vime==0.0.1) (1.5.1)\n",
            "Collecting websockets<12.0 (from lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning (from lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading pytorch_lightning-2.0.2-py3-none-any.whl (719 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.0/719.0 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->vime==0.0.1) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->vime==0.0.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->vime==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->vime==0.0.1) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->vime==0.0.1) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->vime==0.0.1) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->vime==0.0.1) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2.0.0->vime==0.0.1) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2.0.0->vime==0.0.1) (16.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow<3.0,>=1.2.0->lightning>=2.0.0->vime==0.0.1) (2.8.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<6.0,>=4.8.0->lightning>=2.0.0->vime==0.0.1) (2.4.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateutils<2.0->lightning>=2.0.0->vime==0.0.1) (2022.7.1)\n",
            "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff<8.0,>=5.7.0->lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting starlette (from lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading starlette-0.22.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette->lightning>=2.0.0->vime==0.0.1) (3.6.2)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec<2024.0,>=2022.5.0->lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting blessed>=1.19.0 (from inquirer<5.0,>=2.10.0->lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-editor>=1.0.4 (from inquirer<5.0,>=2.10.0->lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Collecting readchar>=3.0.6 (from inquirer<5.0,>=2.10.0->lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<5.0->lightning>=2.0.0->vime==0.0.1) (2.1.2)\n",
            "Collecting pyjwt (from lightning-cloud>=0.5.34->lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading PyJWT-2.7.0-py3-none-any.whl (22 kB)\n",
            "Collecting python-multipart (from lightning-cloud>=0.5.34->lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from lightning-cloud>=0.5.34->lightning>=2.0.0->vime==0.0.1) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning>=2.0.0->vime==0.0.1) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning>=2.0.0->vime==0.0.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning>=2.0.0->vime==0.0.1) (3.4)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning>=2.0.0->vime==0.0.1) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning>=2.0.0->vime==0.0.1) (2.14.0)\n",
            "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from starsessions<2.0,>=1.2.1->lightning>=2.0.0->vime==0.0.1) (2.1.2)\n",
            "Collecting h11>=0.8 (from uvicorn<2.0->lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->vime==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning>=2.0.0->vime==0.0.1) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning>=2.0.0->vime==0.0.1)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->lightning>=2.0.0->vime==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning>=2.0.0->vime==0.0.1) (0.2.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<15.0,>=12.3.0->lightning>=2.0.0->vime==0.0.1) (0.1.2)\n",
            "Requirement already satisfied: setuptools>=41.0 in /usr/local/lib/python3.10/dist-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning>=2.0.0->vime==0.0.1) (67.7.2)\n",
            "Building wheels for collected packages: vime\n",
            "  Building wheel for vime (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vime: filename=vime-0.0.1-py3-none-any.whl size=10621 sha256=4650e164572bd9ccf2ca00b1cd1410459cc0c5c26fd70f7cdd87347b1dc44d4c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p7fvvkn9/wheels/ef/18/af/536655f577a9f4cd8194e69814e6f665db853d66f822393254\n",
            "Successfully built vime\n",
            "Installing collected packages: python-editor, websockets, readchar, python-multipart, pyjwt, ordered-set, multidict, lightning-utilities, h11, frozenlist, blessed, async-timeout, yarl, uvicorn, starlette, inquirer, deepdiff, dateutils, croniter, arrow, aiosignal, starsessions, fastapi, aiohttp, lightning-cloud, torchmetrics, pytorch-lightning, lightning, vime\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 arrow-1.2.3 async-timeout-4.0.2 blessed-1.20.0 croniter-1.3.14 dateutils-0.6.12 deepdiff-6.3.0 fastapi-0.88.0 frozenlist-1.3.3 h11-0.14.0 inquirer-3.1.3 lightning-2.0.2 lightning-cloud-0.5.36 lightning-utilities-0.8.0 multidict-6.0.4 ordered-set-4.1.0 pyjwt-2.7.0 python-editor-1.0.4 python-multipart-0.0.6 pytorch-lightning-2.0.2 readchar-4.0.5 starlette-0.22.0 starsessions-1.3.0 torchmetrics-0.11.4 uvicorn-0.22.0 vime-0.0.1 websockets-11.0.3 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68xM6jF0ZchA"
      },
      "source": [
        "## Prepare MNIST"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easydict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMTTJ6Nscw_a",
        "outputId": "11b39a1a-ae97-4ed2-b45c-9bf2a9c39903"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (1.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "import easydict\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "warnings.filterwarnings(\"ignore\") "
      ],
      "metadata": {
        "id": "3d2SUG3UcRka"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN7RHXuYr88l"
      },
      "source": [
        "- Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZBe2gEgzr-q1"
      },
      "outputs": [],
      "source": [
        "args_mlp = easydict.EasyDict({\n",
        "    \"weights_dirpath\": \"./mlp_weights\",\n",
        "    \"num_classes\": 10,\n",
        "    \"max_epochs\": 50,\n",
        "    \"batch_size\": 64,\n",
        "    \"train_size\": 0.9,\n",
        "    \"lr\": 1e-3, \n",
        "    \"log_interval\": 5,\n",
        "    \"seed\": 26,\n",
        "})\n",
        "args_self = easydict.EasyDict({\n",
        "    \"weights_dirpath\": \"./vimeself_weights\",\n",
        "    \"max_epochs\": 50,\n",
        "    \"batch_size\": 512,\n",
        "    \"train_size\": 0.9,\n",
        "    \"lr\": 1e-2, \n",
        "    \"p_masking\": 0.3,\n",
        "    \"alpha\": 2.0,\n",
        "    \"log_interval\": 5,\n",
        "    \"seed\": 26,\n",
        "})\n",
        "args_semi = easydict.EasyDict({\n",
        "    \"weights_dirpath\": \"./vimesemi_weights\",\n",
        "    \"num_classes\": 10,\n",
        "    \"supervised_criterion\": nn.CrossEntropyLoss(),\n",
        "    \"max_epochs\": 50,\n",
        "    \"labeled_batch_size\": 64,\n",
        "    \"unlabeled_batch_size\": 512,\n",
        "    \"train_size\": 0.9,\n",
        "    \"lr\": 1e-3, \n",
        "    \"p_masking\": 0.3,\n",
        "    \"K\": 3,\n",
        "    \"beta\": 1.0,\n",
        "    \"log_interval\": 5,\n",
        "    \"seed\": 26,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_folder(path: str) -> None:\n",
        "    try:\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "    except OSError as error:\n",
        "        print(error)"
      ],
      "metadata": {
        "id": "sAAMbpDRqGj9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_folder(args_mlp.weights_dirpath)\n",
        "create_folder(args_self.weights_dirpath)\n",
        "create_folder(args_semi.weights_dirpath)"
      ],
      "metadata": {
        "id": "7q8cqk7NqH_1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRrJ4A5RKC4B"
      },
      "source": [
        "- Load data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "yz7eminncyb4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml(\"mnist_784\")"
      ],
      "metadata": {
        "id": "N7JdJZofCXED"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = mnist.data.values\n",
        "target = mnist.target.astype(int).values"
      ],
      "metadata": {
        "id": "CUujD6TFjqVs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data /= 255.0"
      ],
      "metadata": {
        "id": "nu1JV7JhZJhg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_ZB4UZ0gg7m",
        "outputId": "73941cb2-3599-46d1-e2a9-e1c8012d365f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Split data"
      ],
      "metadata": {
        "id": "VyAxwzdFiJpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_labeled_data_used = 1000\n",
        "unlabeled_data_rate = 0.9\n",
        "seed = 26"
      ],
      "metadata": {
        "id": "mvJecY3xh56g"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, X_test, y, y_test = train_test_split(data, target, test_size=1/7, random_state=seed, stratify=target)"
      ],
      "metadata": {
        "id": "2WHvI1h1rW3p"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_labeled, X_unlabeled, y, _ = train_test_split(X, y, test_size=unlabeled_data_rate, random_state=seed, stratify=y)"
      ],
      "metadata": {
        "id": "T3ADeqVXrpV5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_labeled = X_labeled[:num_labeled_data_used]\n",
        "y = y[:num_labeled_data_used]"
      ],
      "metadata": {
        "id": "AQIirdQvsh0I"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supervised Model"
      ],
      "metadata": {
        "id": "Qku-9G9uX-ao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightning.pytorch as pl\n",
        "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import accuracy_score\n",
        "from vime.datamodules import LabeledDataModule\n",
        "from vime.lightningmodules import MLPClassifier"
      ],
      "metadata": {
        "id": "vQo6GkJqUDgi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create datamodule and model"
      ],
      "metadata": {
        "id": "ruYWDsF4aGeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim = X_labeled.shape[1]"
      ],
      "metadata": {
        "id": "V4jkchdNZsY2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_datamodule = LabeledDataModule(\n",
        "    X_labeled, y, X_test,\n",
        "    train_size=args_mlp.train_size,\n",
        "    batch_size=args_mlp.batch_size,\n",
        "    seed=args_mlp.seed,\n",
        ")"
      ],
      "metadata": {
        "id": "PmSvyN-5SE5t"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_classifier = MLPClassifier(\n",
        "    input_dim=dim,\n",
        "    hidden_dims=[512, 256, 128],\n",
        "    num_classes=args_mlp.num_classes,\n",
        "    lr=args_mlp.lr,\n",
        "    log_interval=args_mlp.log_interval,\n",
        "    seed=args_mlp.seed,\n",
        ")"
      ],
      "metadata": {
        "id": "R_OFe4CI5Unw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913ab290-079d-458b-f9a7-9969b11e611d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Global seed set to 26\n",
            "INFO:lightning.fabric.utilities.seed:Global seed set to 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train supervised model"
      ],
      "metadata": {
        "id": "4DSj_GKnaMSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    dirpath=args_mlp.weights_dirpath,\n",
        "    filename=\"mlp\",\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    save_weights_only=True,\n",
        ")\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=10,\n",
        "    mode=\"min\",\n",
        ")\n",
        "trainer = pl.Trainer(\n",
        "    accelerator=\"gpu\",\n",
        "    devices=1,\n",
        "    logger=False,\n",
        "    callbacks=[checkpoint, early_stop],\n",
        "    max_epochs=args_mlp.max_epochs,\n",
        "    num_sanity_val_steps=0,\n",
        "    enable_progress_bar=False, \n",
        "    enable_model_summary=False,\n",
        "    deterministic=True,\n",
        ")"
      ],
      "metadata": {
        "id": "Ls6dr95b4tPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3d34a1a-042e-4d36-eb55-f1f70209ee05"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(mlp_classifier, labeled_datamodule)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYsZODDyFwGd",
        "outputId": "aa2fcef9-ce14-42c2-c8d5-8af088886b06"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 1.5906 | Val Macro Acc: 0.6977\n",
            "Epoch 1 | Train Loss: 1.0895  Val Loss: 0.5416 | Val Macro Acc: 0.8029\n",
            "Epoch 5 | Train Loss: 0.1458  Val Loss: 0.5540 | Val Macro Acc: 0.8152\n",
            "Epoch 10 | Train Loss: 0.1133  Val Loss: 0.5382 | Val Macro Acc: 0.8274\n",
            "Epoch 15 | Train Loss: 0.0826  Val Loss: 0.4827 | Val Macro Acc: 0.8662\n",
            "Epoch 20 | Train Loss: 0.0374  Val Loss: 0.6857 | Val Macro Acc: 0.7724\n",
            "Epoch 25 | Train Loss: 0.1387  Val Loss: 0.6290 | Val Macro Acc: 0.7959\n",
            "Epoch 30 | Train Loss: 0.0981  "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Test supervised model"
      ],
      "metadata": {
        "id": "0x862LyGWoP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = trainer.predict(mlp_classifier, labeled_datamodule, ckpt_path=\"best\")\n",
        "pred = np.concatenate(pred).argmax(1)"
      ],
      "metadata": {
        "id": "2MD3zmeJeRu3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe142a7e-d7f8-4d05-88bc-ccd4bc47ee60"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Restoring states from the checkpoint path at /content/drive/MyDrive/Colab Notebooks/vime/mlp_weights/mlp-v8.ckpt\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Restoring states from the checkpoint path at /content/drive/MyDrive/Colab Notebooks/vime/mlp_weights/mlp-v8.ckpt\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: Loaded model weights from the checkpoint at /content/drive/MyDrive/Colab Notebooks/vime/mlp_weights/mlp-v8.ckpt\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Loaded model weights from the checkpoint at /content/drive/MyDrive/Colab Notebooks/vime/mlp_weights/mlp-v8.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, pred)"
      ],
      "metadata": {
        "id": "-415DvwKeZEX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b775a12e-6b39-429f-a2d1-a79771a5c5ad"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8883"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VIME"
      ],
      "metadata": {
        "id": "Sk00Z9pJiTUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vime import VIMESelf, VIMESelfDataModule, VIMESemi, VIMESemiDataModule"
      ],
      "metadata": {
        "id": "mt9e_MtDS5nV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VIME Self"
      ],
      "metadata": {
        "id": "9fPv2ys9lGrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create datamodule and model"
      ],
      "metadata": {
        "id": "wCKRinaBmf31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim = X_unlabeled.shape[1]"
      ],
      "metadata": {
        "id": "XUAY2nfcIgfq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "self_datamodule = VIMESelfDataModule(\n",
        "    X_unlabeled,\n",
        "    train_size=args_self.train_size,\n",
        "    batch_size=args_self.batch_size,\n",
        "    seed=args_self.seed,\n",
        ")"
      ],
      "metadata": {
        "id": "R9QxnpdZJK_K"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vime_self = VIMESelf(\n",
        "    input_dim=dim,\n",
        "    hidden_dims=[512, 256, 128],\n",
        "    lr=args_self.lr,\n",
        "    p_masking=args_self.p_masking,\n",
        "    alpha=args_self.alpha,\n",
        "    log_interval=args_self.log_interval,\n",
        "    seed=args_self.seed,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8OQbsLjl-LW",
        "outputId": "2cf7e14a-37e4-4066-f061-db292fd9831c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Global seed set to 26\n",
            "INFO:lightning.fabric.utilities.seed:Global seed set to 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train vime self"
      ],
      "metadata": {
        "id": "YboyGahYLbtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    dirpath=args_self.weights_dirpath,\n",
        "    filename=\"vime_self\",\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    save_weights_only=True,\n",
        ")\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=10,\n",
        "    mode=\"min\",\n",
        ")\n",
        "trainer = pl.Trainer(\n",
        "    accelerator=\"gpu\",\n",
        "    devices=1,\n",
        "    logger=False,\n",
        "    callbacks=[checkpoint, early_stop],\n",
        "    max_epochs=args_self.max_epochs,\n",
        "    num_sanity_val_steps=0,\n",
        "    enable_progress_bar=False, \n",
        "    enable_model_summary=False,\n",
        "    deterministic=True,\n",
        ")"
      ],
      "metadata": {
        "id": "-QQ0TjD6pgRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b112b8e6-9540-4fb6-8e26-714022cc83cb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(vime_self, self_datamodule)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWmpH4bvrZ6r",
        "outputId": "b0f820de-d41e-4d59-a621-bc44d6b9a489"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.1562 | Val Loss_m: 0.0957 | Val Loss_r: 0.0302\n",
            "Epoch 1 | Train Loss: 0.3436 | Train Loss_m: 0.2508 | Train Loss_r: 0.0464  Val Loss: 0.1155 | Val Loss_m: 0.0839 | Val Loss_r: 0.0158\n",
            "Epoch 5 | Train Loss: 0.2534 | Train Loss_m: 0.2179 | Train Loss_r: 0.0178  Val Loss: 0.1105 | Val Loss_m: 0.0842 | Val Loss_r: 0.0132\n",
            "Epoch 10 | Train Loss: 0.2463 | Train Loss_m: 0.2156 | Train Loss_r: 0.0154  Val Loss: 0.1018 | Val Loss_m: 0.0783 | Val Loss_r: 0.0118\n",
            "Epoch 15 | Train Loss: 0.2420 | Train Loss_m: 0.2124 | Train Loss_r: 0.0148  Val Loss: 0.1007 | Val Loss_m: 0.0771 | Val Loss_r: 0.0118\n",
            "Epoch 20 | Train Loss: 0.2381 | Train Loss_m: 0.2091 | Train Loss_r: 0.0145  Val Loss: 0.0977 | Val Loss_m: 0.0744 | Val Loss_r: 0.0117\n",
            "Epoch 25 | Train Loss: 0.2353 | Train Loss_m: 0.2064 | Train Loss_r: 0.0145  Val Loss: 0.0979 | Val Loss_m: 0.0738 | Val Loss_r: 0.0120\n",
            "Epoch 30 | Train Loss: 0.2334 | Train Loss_m: 0.2042 | Train Loss_r: 0.0146  Val Loss: 0.0936 | Val Loss_m: 0.0702 | Val Loss_r: 0.0117\n",
            "Epoch 35 | Train Loss: 0.2317 | Train Loss_m: 0.2025 | Train Loss_r: 0.0146  Val Loss: 0.0955 | Val Loss_m: 0.0716 | Val Loss_r: 0.0119\n",
            "Epoch 40 | Train Loss: 0.2306 | Train Loss_m: 0.2013 | Train Loss_r: 0.0147  Val Loss: 0.0961 | Val Loss_m: 0.0716 | Val Loss_r: 0.0122\n",
            "Epoch 45 | Train Loss: 0.2299 | Train Loss_m: 0.2005 | Train Loss_r: 0.0147  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0915 | Val Loss_m: 0.0675 | Val Loss_r: 0.0120\n",
            "Epoch 50 | Train Loss: 0.2290 | Train Loss_m: 0.1997 | Train Loss_r: 0.0147  "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_path = checkpoint.best_model_path"
      ],
      "metadata": {
        "id": "LA5UYnLG_jCa"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vime_self_best = VIMESelf.load_from_checkpoint(best_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRq6_xiSivq8",
        "outputId": "d2809536-ffa7-4647-c667-fc7884e4be5e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Global seed set to 26\n",
            "INFO:lightning.fabric.utilities.seed:Global seed set to 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_encoder = vime_self_best.encoder"
      ],
      "metadata": {
        "id": "kbs1mKr8j1ar"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train supervised model from pretrained encoder"
      ],
      "metadata": {
        "id": "vrUbZOYzWlGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    Z = pretrained_encoder(torch.tensor(X_labeled, dtype=torch.float32).cuda())\n",
        "    Z_test = pretrained_encoder(torch.tensor(X_test, dtype=torch.float32).cuda())"
      ],
      "metadata": {
        "id": "17LF83fPqCFL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z = Z.cpu().numpy()\n",
        "Z_test = Z_test.cpu().numpy()"
      ],
      "metadata": {
        "id": "WuNayirSHMe0"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_datamodule_from_unsupervised = LabeledDataModule(Z, y, Z_test, train_size=args_mlp.train_size, batch_size=args_mlp.batch_size, seed=args_mlp.seed)"
      ],
      "metadata": {
        "id": "e1aZzXjWqBtc"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_classifier = MLPClassifier(\n",
        "    input_dim=128,\n",
        "    hidden_dims=[64, 32],\n",
        "    num_classes=args_mlp.num_classes,\n",
        "    lr=args_mlp.lr,\n",
        "    seed=args_mlp.seed,\n",
        ")"
      ],
      "metadata": {
        "id": "IUk2pPpUXL7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2680ce22-d091-46b0-e0d6-d891aadbb47d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Global seed set to 26\n",
            "INFO:lightning.fabric.utilities.seed:Global seed set to 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    dirpath=args_mlp.weights_dirpath,\n",
        "    filename=\"mlp_from_unsupervised\",\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    save_weights_only=True,\n",
        ")\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=10,\n",
        "    mode=\"min\",\n",
        ")\n",
        "trainer = pl.Trainer(\n",
        "    accelerator=\"gpu\",\n",
        "    devices=1,\n",
        "    logger=False,\n",
        "    callbacks=[checkpoint, early_stop],\n",
        "    max_epochs=args_mlp.max_epochs,\n",
        "    num_sanity_val_steps=0,\n",
        "    enable_progress_bar=False, \n",
        "    enable_model_summary=False,\n",
        "    deterministic=True,\n",
        ")"
      ],
      "metadata": {
        "id": "-BpUmQ5WSAAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccfb9aae-869c-4b45-cc6e-25de6688cdc5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(mlp_classifier, labeled_datamodule_from_unsupervised)"
      ],
      "metadata": {
        "id": "6J3KyJcBXIFJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8aa656c-b183-4514-a4a6-9f4b8e14ac1a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 2.2118 | Val Macro Acc: 0.1578\n",
            "Epoch 1 | Train Loss: 2.0487  Val Loss: 0.6566 | Val Macro Acc: 0.8467\n",
            "Epoch 10 | Train Loss: 0.5176  Val Loss: 0.4887 | Val Macro Acc: 0.8617\n",
            "Epoch 20 | Train Loss: 0.2015  Val Loss: 0.4214 | Val Macro Acc: 0.8679\n",
            "Epoch 30 | Train Loss: 0.1038  Val Loss: 0.4393 | Val Macro Acc: 0.8728\n",
            "Epoch 40 | Train Loss: 0.0750  "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Test vime self"
      ],
      "metadata": {
        "id": "l7C8Xw9kfedG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = trainer.predict(mlp_classifier, labeled_datamodule_from_unsupervised, ckpt_path=\"best\")\n",
        "pred = np.concatenate(pred).argmax(1)"
      ],
      "metadata": {
        "id": "QxOL0k7rfXg4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b58a1fa-003d-4444-cbea-72f942035573"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Restoring states from the checkpoint path at /content/drive/MyDrive/Colab Notebooks/vime/mlp_weights/mlp_from_unsupervised-v1.ckpt\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Restoring states from the checkpoint path at /content/drive/MyDrive/Colab Notebooks/vime/mlp_weights/mlp_from_unsupervised-v1.ckpt\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: Loaded model weights from the checkpoint at /content/drive/MyDrive/Colab Notebooks/vime/mlp_weights/mlp_from_unsupervised-v1.ckpt\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Loaded model weights from the checkpoint at /content/drive/MyDrive/Colab Notebooks/vime/mlp_weights/mlp_from_unsupervised-v1.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, pred)"
      ],
      "metadata": {
        "id": "TawbZLb9XsEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e6d87e6-96b5-4160-8865-250eb0814907"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8983"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VIME Semi"
      ],
      "metadata": {
        "id": "0GyrAB0WkAsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create datamodule and model"
      ],
      "metadata": {
        "id": "4XNHwOUDkFEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim = X_labeled.shape[1]"
      ],
      "metadata": {
        "id": "sUzVLATbkGka"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "semi_datamodule = VIMESemiDataModule(\n",
        "    X_unlabeled,\n",
        "    X_labeled,\n",
        "    y,\n",
        "    X_test,\n",
        "    train_size=args_semi.train_size,\n",
        "    labeled_batch_size=args_semi.labeled_batch_size,\n",
        "    unlabeled_batch_size=args_semi.unlabeled_batch_size,\n",
        "    seed=args_semi.seed,\n",
        ")"
      ],
      "metadata": {
        "id": "O606x9hWkJS7"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vime_semi = VIMESemi(\n",
        "    pretrained_encoder=pretrained_encoder,\n",
        "    hidden_dims=[512, 256, 128],\n",
        "    num_classes=args_semi.num_classes,\n",
        "    supervised_criterion=args_semi.supervised_criterion,\n",
        "    lr=args_semi.lr,\n",
        "    p_masking=args_semi.p_masking,\n",
        "    K=args_semi.K,\n",
        "    beta=args_semi.beta,\n",
        "    log_interval=args_semi.log_interval,\n",
        "    seed=args_semi.seed,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJje5q80j7XT",
        "outputId": "3fb17f27-88e6-4d43-847a-dac8100141b3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Global seed set to 26\n",
            "INFO:lightning.fabric.utilities.seed:Global seed set to 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train vime semi"
      ],
      "metadata": {
        "id": "pBZJVPIvuQ4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    dirpath=args_semi.weights_dirpath,\n",
        "    filename=\"vime_semi\",\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    save_weights_only=True,\n",
        ")\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=20,\n",
        "    mode=\"min\",\n",
        ")"
      ],
      "metadata": {
        "id": "Wd6qnZBflzuz"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(\n",
        "    accelerator=\"gpu\",\n",
        "    devices=1,\n",
        "    logger=False,\n",
        "    callbacks=[checkpoint, early_stop],\n",
        "    max_epochs=args_semi.max_epochs,\n",
        "    num_sanity_val_steps=0,\n",
        "    enable_progress_bar=False, \n",
        "    enable_model_summary=False,\n",
        "    deterministic=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR7JwkFnmTzi",
        "outputId": "db201d5a-bf46-41ff-b348-3032b168119c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(vime_semi, semi_datamodule)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZTVOGenmV1S",
        "outputId": "bb092c00-bf97-415c-fdd1-7af3876887f8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss_s: 1.2711\n",
            "Epoch 1 | Train Loss: 1.2933 | Train Loss_s: 1.2183 | Train Loss_u: 0.0749  Val Loss_s: 0.4205\n",
            "Epoch 5 | Train Loss: 0.3440 | Train Loss_s: 0.2292 | Train Loss_u: 0.1149  Val Loss_s: 0.4209\n",
            "Epoch 10 | Train Loss: 0.2554 | Train Loss_s: 0.1380 | Train Loss_u: 0.1174  Val Loss_s: 0.4465\n",
            "Epoch 15 | Train Loss: 0.2519 | Train Loss_s: 0.1401 | Train Loss_u: 0.1117  Val Loss_s: 0.4063\n",
            "Epoch 20 | Train Loss: 0.2080 | Train Loss_s: 0.0985 | Train Loss_u: 0.1095  Val Loss_s: 0.4454\n",
            "Epoch 25 | Train Loss: 0.2183 | Train Loss_s: 0.1045 | Train Loss_u: 0.1138  Val Loss_s: 0.4739\n",
            "Epoch 30 | Train Loss: 0.2012 | Train Loss_s: 0.0911 | Train Loss_u: 0.1101  Val Loss_s: 0.4263\n",
            "Epoch 35 | Train Loss: 0.1735 | Train Loss_s: 0.0715 | Train Loss_u: 0.1019  "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Test vime semi"
      ],
      "metadata": {
        "id": "j-XUwx5MfZvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = trainer.predict(vime_semi, semi_datamodule, ckpt_path=\"best\")\n",
        "pred = np.concatenate(pred).argmax(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgxmkrDLruVA",
        "outputId": "accef49b-e422-48ae-9db2-3eaba50ba5a4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Restoring states from the checkpoint path at /content/drive/MyDrive/Colab Notebooks/vime/vimesemi_weights/vime_semi.ckpt\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Restoring states from the checkpoint path at /content/drive/MyDrive/Colab Notebooks/vime/vimesemi_weights/vime_semi.ckpt\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: Loaded model weights from the checkpoint at /content/drive/MyDrive/Colab Notebooks/vime/vimesemi_weights/vime_semi.ckpt\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Loaded model weights from the checkpoint at /content/drive/MyDrive/Colab Notebooks/vime/vimesemi_weights/vime_semi.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTcKCD-he2o6",
        "outputId": "c7b5329f-e426-4a46-f1b7-08307a008251"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9214"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9k9did4sfssE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}